{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1732181925083,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "NZLKEFGqpkza"
   },
   "outputs": [],
   "source": [
    "from random import randint, choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kMDITdMpkzc"
   },
   "source": [
    "# Map Reduce\n",
    "\n",
    "In the part of the assignment you are requested to use Map Reduce paradigm to solve the following exercises.\n",
    "\n",
    "**NOTE THAT**: **A solution that does not use map reduce is not valid!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UvFKq5Dpkzd"
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "You have a list of dictionaries, each representing a student with the following properties: a name and an array of test scores. Your task is to use map, filter, and reduce to calculate the average test score for each student, and then return a list of dictionaries containing only the students whose average score is above 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XnZxeOdtpkze"
   },
   "outputs": [],
   "source": [
    "students = [\n",
    "    {\"name\": \"Alice\", \"scores\": [95, 92, 88, 100]},\n",
    "    {\"name\": \"Bob\", \"scores\": [78, 81, 85, 80]},\n",
    "    {\"name\": \"Charlie\", \"scores\": [99, 91, 94, 96]},\n",
    "    {\"name\": \"Diana\", \"scores\": [85, 87, 89, 83]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WopOVxHSpkzf"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JGYCqweYpkzf",
    "outputId": "89230ab4-a15a-4ae5-84a3-9eb13573a4a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Alice', 'average_score': 93.75},\n",
       " {'name': 'Charlie', 'average_score': 95.0}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"name\": \"Alice\", \"average_score\": 93.75},\n",
    "    {\"name\": \"Charlie\", \"average_score\": 95.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG5h3pN1pkzg"
   },
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1732181928585,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "3ZB3sFT_pkzh",
    "outputId": "cf486e14-4d6f-455d-8f69-19096dfe9831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Student 1', 'scores': [95, 98, 73, 66, 95]},\n",
       " {'name': 'Student 2', 'scores': [87, 62, 78, 73, 52]},\n",
       " {'name': 'Student 3', 'scores': [77, 69, 51, 93, 97]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_student_dataset(num_students=50):\n",
    "    names = [f\"Student {i}\" for i in range(1, num_students + 1)]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"scores\": [randint(50, 100) for _ in range(randint(3, 6))]  # Random scores between 50 and 100\n",
    "        }\n",
    "        for name in names\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_student_dataset = generate_random_student_dataset(50)\n",
    "random_student_dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MHi3FLeWpkzi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Dataset (First 3 Students):\n",
      "[{'name': 'Student-1', 'scores': [54, 50, 91, 84, 88]}, {'name': 'Student-2', 'scores': [97, 69, 76, 75, 80, 75]}, {'name': 'Student-3', 'scores': [54, 79, 88, 77, 54, 72]}]\n",
      "\n",
      "Filtered Students with Average Score > 90:\n",
      "[{'name': 'Student-28', 'average_score': 95.25}]\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "from random import randint\n",
    "from functools import reduce\n",
    "\n",
    "# Function to generate a random student dataset\n",
    "def generate_random_student_dataset(num_students=50):\n",
    "    names = [f\"Student-{i}\" for i in range(1, num_students + 1)]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"scores\": [randint(50, 100) for _ in range(randint(3, 6))]  # Random scores between 50 and 100\n",
    "        }\n",
    "        for name in names\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "# Function to process the student dataset\n",
    "def process_students(students):\n",
    "    # Step 1: Calculate average score for each student\n",
    "    students_with_avg = list(\n",
    "        map(\n",
    "            lambda student: {\n",
    "                \"name\": student[\"name\"],\n",
    "                \"average_score\": reduce(lambda x, y: x + y, student[\"scores\"]) / len(student[\"scores\"])\n",
    "            },\n",
    "            students,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Step 2: Filter students with average score > 90\n",
    "    filtered_students = list(filter(lambda student: student[\"average_score\"] > 90, students_with_avg))\n",
    "\n",
    "    # Step 3: Format the output\n",
    "    result = list(\n",
    "        map(lambda student: {\"name\": student[\"name\"], \"average_score\": student[\"average_score\"]}, filtered_students)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "# Generate the random dataset\n",
    "random_student_dataset = generate_random_student_dataset(50)\n",
    "\n",
    "# Process the dataset\n",
    "output = process_students(random_student_dataset)\n",
    "\n",
    "# Display the first few random students and the final result\n",
    "print(\"Random Dataset (First 3 Students):\")\n",
    "print(random_student_dataset[:3])\n",
    "print(\"\\nFiltered Students with Average Score > 90:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWL_3xWNpkzj"
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "You have a list of dictionaries, each representing a product with the following properties: name, price, and category. Using the functions `map`, `filter`, and `reduce`, calculate the average price of the products in each category and return a list of dictionaries containing only the categories where the average price exceeds 50.\n",
    "\n",
    "Example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wwk7f8Ihpkzk"
   },
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\"name\": \"Product A\", \"price\": 60, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product B\", \"price\": 40, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product C\", \"price\": 70, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product D\", \"price\": 30, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product E\", \"price\": 90, \"category\": \"Sports\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agz3cP7Ppkzl"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LbFtUV_apkzl",
    "outputId": "745cdcbe-7320-4a08-de7b-0e1bcb84473e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': 'Electronics', 'average_price': 50.0},\n",
       " {'category': 'Sports', 'average_price': 90.0}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"category\": \"Electronics\", \"average_price\": 50.0},\n",
    "    {\"category\": \"Sports\", \"average_price\": 90.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKBEAQE3pkzl"
   },
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1732181933353,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "0qj_9nZSpkzm",
    "outputId": "7bab35c7-84d0-4603-a1da-dc4a76768179"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Product 1', 'price': 153, 'category': 'Books'},\n",
       " {'name': 'Product 2', 'price': 176, 'category': 'Books'},\n",
       " {'name': 'Product 3', 'price': 153, 'category': 'Electronics'},\n",
       " {'name': 'Product 4', 'price': 101, 'category': 'Books'},\n",
       " {'name': 'Product 5', 'price': 22, 'category': 'Home'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_product_dataset(num_products=100):\n",
    "    categories = [\"Electronics\", \"Home\", \"Sports\", \"Books\", \"Clothing\", \"Toys\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Product {i}\",\n",
    "            \"price\": randint(10, 200),  # Random price between 10 and 200\n",
    "            \"category\": choice(categories),  # Randomly choose a category\n",
    "        }\n",
    "        for i in range(1, num_products + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "# Example of using the function\n",
    "random_dataset = generate_random_product_dataset(100)\n",
    "random_dataset[:5]  # Display the first 5 entries to check the dataset structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AG9V3Wt7pkzm"
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# hints: 1) Group products by category (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average price for each category and filter categories with an average price > 50\n",
    "from functools import reduce\n",
    "from random import randint, choice\n",
    "\n",
    "# Example dataset\n",
    "products = [\n",
    "    {\"name\": \"Product A\", \"price\": 60, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product B\", \"price\": 40, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product C\", \"price\": 70, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product D\", \"price\": 30, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product E\", \"price\": 90, \"category\": \"Sports\"},\n",
    "]\n",
    "\n",
    "# Step 1: Group by category using reduce\n",
    "grouped = reduce(lambda acc, product: acc.update({product['category']: acc.get(product['category'], []) + [product]}) or acc, products, {})\n",
    "\n",
    "# Step 2: Calculate average prices using map\n",
    "average_prices = list(map(lambda category: {\"category\": category, \"average_price\": sum(p['price'] for p in grouped[category]) / len(grouped[category])}, grouped))\n",
    "\n",
    "# Step 3: Filter categories where average price > 50\n",
    "result = list(filter(lambda cat: cat['average_price'] > 50, average_prices))\n",
    "\n",
    "# Output the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hivtZEf7pkzm"
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "You have a list of dictionaries, each representing an employee with the following properties: name, salary, and department. Your task is to use `map`, `filter`, and `reduce` to calculate the average salary for each department and return a list of dictionaries containing only the departments where the average salary is above 65,000.\n",
    "\n",
    "**Example Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1732181936402,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "N8vjLRHxpkzm"
   },
   "outputs": [],
   "source": [
    "employees = [\n",
    "    {\"name\": \"John\", \"salary\": 70000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Jane\", \"salary\": 75000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Alice\", \"salary\": 60000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Bob\", \"salary\": 68000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Charlie\", \"salary\": 90000, \"department\": \"Marketing\"},\n",
    "    {\"name\": \"Diana\", \"salary\": 50000, \"department\": \"Marketing\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otSniMO7pkzm"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Kx4HT8RXpkzn",
    "outputId": "8653ff13-815d-4040-c68e-fc4a6825134d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'department': 'Engineering', 'average_salary': 72500.0},\n",
       " {'department': 'Marketing', 'average_salary': 70000.0}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"department\": \"Engineering\", \"average_salary\": 72500.0},\n",
    "    {\"department\": \"Marketing\", \"average_salary\": 70000.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD_xlB78pkzn"
   },
   "source": [
    "### Test\n",
    "\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1732181939215,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "RhR9JLK-pkzn",
    "outputId": "72bc934d-4d3c-477e-cf84-3cf1d8fae61a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Employee 1', 'salary': 112097, 'department': 'HR'},\n",
       " {'name': 'Employee 2', 'salary': 87788, 'department': 'Engineering'},\n",
       " {'name': 'Employee 3', 'salary': 66561, 'department': 'Finance'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_employee_dataset(num_employees=50):\n",
    "    departments = [\"Engineering\", \"HR\", \"Marketing\", \"Sales\", \"Finance\", \"IT\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Employee {i}\",\n",
    "            \"salary\": randint(40000, 120000),  # Random salary between 40,000 and 120,000\n",
    "            \"department\": choice(departments)  # Randomly choose a department\n",
    "        }\n",
    "        for i in range(1, num_employees + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_employee_dataset = generate_random_employee_dataset(50)\n",
    "\n",
    "random_employee_dataset[:3]  # Display the first 3 entries of each dataset for checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pt9m6NK-pkzo"
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# hints: 1) Group employees' salaries by department (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average salary for each department and filter departments with an average salary > threshold\n",
    "from functools import reduce\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "# Input data\n",
    "employees = [\n",
    "    {\"name\": \"John\", \"salary\": 70000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Jane\", \"salary\": 75000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Alice\", \"salary\": 60000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Bob\", \"salary\": 68000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Charlie\", \"salary\": 90000, \"department\": \"Marketing\"},\n",
    "    {\"name\": \"Diana\", \"salary\": 50000, \"department\": \"Marketing\"},\n",
    "]\n",
    "\n",
    "# Group employees by department\n",
    "employees.sort(key=itemgetter('department'))\n",
    "grouped = groupby(employees, key=itemgetter('department'))\n",
    "\n",
    "# Calculate average salary per department\n",
    "department_avg_salary = map(\n",
    "    lambda dept: {\n",
    "        \"department\": dept[0],\n",
    "        \"average_salary\": reduce(\n",
    "            lambda acc, emp: acc + emp[\"salary\"], dept[1], 0\n",
    "        ) / len(list(dept[1]))\n",
    "    },\n",
    "    grouped\n",
    ")\n",
    "\n",
    "# Filter departments with average salary > 65000\n",
    "filtered_departments = filter(\n",
    "    lambda dept: dept[\"average_salary\"] > 65000, department_avg_salary\n",
    ")\n",
    "\n",
    "# Convert result to list\n",
    "result = list(filtered_departments)\n",
    "\n",
    "# Output\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzxr0v2Rpkzo"
   },
   "source": [
    "# Biopython\n",
    "\n",
    "Write the following five functions to analyze global alignments between two sequences using Biopython's `pairwise2` module:\n",
    "\n",
    "1. **countMatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment (pairwise2.globalxx) of the same length. It returns the number of positions where the elements of both sequences match.\n",
    "\n",
    "2. **countMismatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of positions where the elements of the two sequences are different (i.e., they are not gaps, and the characters do not match).\n",
    "\n",
    "3. **countGapOpens(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap openings in the alignment (a gap is opened when a '-' appears in the sequence).\n",
    "\n",
    "4. **countGapExtensions(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap extensions (where '-' continues in the alignment after an initial gap is opened).\n",
    "\n",
    "5. **getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment and returns the alignment score based on the provided scoring scheme: `matchScore` for matches, `mismatchPenalty` for mismatches, `gapOpenPenalty` for opening a gap, and `gapExtensionPenalty` for extending a gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PIaf6BUpkzo"
   },
   "outputs": [],
   "source": [
    "# Add your functions here\n",
    "from Bio import pairwise2\n",
    "\n",
    "# Function 1: Count Matches\n",
    "def countMatches(s1, s2):\n",
    "    \"\"\"Returns the number of matching positions in the aligned sequences.\"\"\"\n",
    "    return sum(1 for a, b in zip(s1, s2) if a == b and a != '-')\n",
    "\n",
    "# Function 2: Count Mismatches\n",
    "def countMismatches(s1, s2):\n",
    "    \"\"\"Returns the number of mismatched positions (non-gaps that differ).\"\"\"\n",
    "    return sum(1 for a, b in zip(s1, s2) if a != b and a != '-' and b != '-')\n",
    "\n",
    "# Function 3: Count Gap Opens\n",
    "def countGapOpens(s1, s2):\n",
    "    \"\"\"Returns the number of gap openings in the alignment.\"\"\"\n",
    "    gaps = 0\n",
    "    for a, b in zip(s1, s2):\n",
    "        if (a == '-' or b == '-') and not (a == b == '-'):\n",
    "            gaps += 1\n",
    "    return gaps\n",
    "\n",
    "# Function 4: Count Gap Extensions\n",
    "def countGapExtensions(s1, s2):\n",
    "    \"\"\"Returns the number of gap extensions in the alignment.\"\"\"\n",
    "    extensions = 0\n",
    "    previous_gap = False\n",
    "    for a, b in zip(s1, s2):\n",
    "        if a == '-' or b == '-':\n",
    "            if previous_gap:  # If continuing a gap\n",
    "                extensions += 1\n",
    "            previous_gap = True\n",
    "        else:\n",
    "            previous_gap = False\n",
    "    return extensions\n",
    "\n",
    "# Function 5: Get Score\n",
    "def getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty):\n",
    "    \"\"\"Returns the alignment score based on the given scoring scheme.\"\"\"\n",
    "    score = 0\n",
    "    previous_gap = False\n",
    "\n",
    "    for a, b in zip(s1, s2):\n",
    "        if a == b and a != '-':  # Match\n",
    "            score += matchScore\n",
    "        elif a != b and a != '-' and b != '-':  # Mismatch\n",
    "            score -= mismatchPenalty\n",
    "        elif a == '-' or b == '-':  # Gap\n",
    "            if previous_gap:  # Gap extension\n",
    "                score -= gapExtensionPenalty\n",
    "            else:  # Gap opening\n",
    "                score -= gapOpenPenalty\n",
    "                previous_gap = True\n",
    "        else:\n",
    "            previous_gap = False  # Reset gap tracking if no gap\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Input sequences\n",
    "    seq1 = \"ACGTACGT\"\n",
    "    seq2 = \"ACGTCG-T\"\n",
    "\n",
    "    # Perform global alignment\n",
    "    alignments = pairwise2.align.globalxx(seq1, seq2)\n",
    "    aligned_s1, aligned_s2 = alignments[0][:2]  # Extract aligned sequences\n",
    "\n",
    "    # Example scoring\n",
    "    match = 2\n",
    "    mismatch = -1\n",
    "    gap_open = -2\n",
    "    gap_extend = -1\n",
    "\n",
    "    # Test functions\n",
    "    print(\"Aligned Sequences:\")\n",
    "    print(aligned_s1)\n",
    "    print(aligned_s2)\n",
    "    print(\"Matches:\", countMatches(aligned_s1, aligned_s2))\n",
    "    print(\"Mismatches:\", countMismatches(aligned_s1, aligned_s2))\n",
    "    print(\"Gap Opens:\", countGapOpens(aligned_s1, aligned_s2))\n",
    "    print(\"Gap Extensions:\", countGapExtensions(aligned_s1, aligned_s2))\n",
    "    print(\"Score:\", getScore(aligned_s1, aligned_s2, match, mismatch, gap_open, gap_extend))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81O19v1fpkzo"
   },
   "source": [
    "### Test\n",
    "Align the sequences of the [Interleukin-12](https://en.wikipedia.org/wiki/Interleukin_12) chain A (denoted as `s1`) from the file [`IL12A.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12A.fasta) and the Interleukin-12 chain B (denoted as `s2`) from the file [`IL12B.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12B.fasta) and check the score as computed from pairwise2 and from your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBhfr3jepkzp"
   },
   "outputs": [],
   "source": [
    "# add the output of the test here\n",
    "from Bio import SeqIO\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "\n",
    "# Reuse the previously defined functions\n",
    "def countMatches(s1, s2):\n",
    "    return sum(1 for a, b in zip(s1, s2) if a == b and a != '-')\n",
    "\n",
    "def countMismatches(s1, s2):\n",
    "    return sum(1 for a, b in zip(s1, s2) if a != b and a != '-' and b != '-')\n",
    "\n",
    "def countGapOpens(s1, s2):\n",
    "    gaps = 0\n",
    "    for a, b in zip(s1, s2):\n",
    "        if (a == '-' or b == '-') and not (a == b == '-'):\n",
    "            gaps += 1\n",
    "    return gaps\n",
    "\n",
    "def countGapExtensions(s1, s2):\n",
    "    extensions = 0\n",
    "    previous_gap = False\n",
    "    for a, b in zip(s1, s2):\n",
    "        if a == '-' or b == '-':\n",
    "            if previous_gap:  # Continuing a gap\n",
    "                extensions += 1\n",
    "            previous_gap = True\n",
    "        else:\n",
    "            previous_gap = False\n",
    "    return extensions\n",
    "\n",
    "def getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty):\n",
    "    score = 0\n",
    "    previous_gap = False\n",
    "\n",
    "    for a, b in zip(s1, s2):\n",
    "        if a == b and a != '-':  # Match\n",
    "            score += matchScore\n",
    "        elif a != b and a != '-' and b != '-':  # Mismatch\n",
    "            score -= mismatchPenalty\n",
    "        elif a == '-' or b == '-':  # Gap\n",
    "            if previous_gap:  # Gap extension\n",
    "                score -= gapExtensionPenalty\n",
    "            else:  # Gap opening\n",
    "                score -= gapOpenPenalty\n",
    "                previous_gap = True\n",
    "        else:\n",
    "            previous_gap = False  # Reset gap tracking\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Testing with IL12A.fasta and IL12B.fasta\n",
    "def test_alignment(file1, file2):\n",
    "    # Read the sequences from FASTA files\n",
    "    seq1 = str(next(SeqIO.parse(file1, \"fasta\")).seq)\n",
    "    seq2 = str(next(SeqIO.parse(file2, \"fasta\")).seq)\n",
    "\n",
    "    # Perform global alignment\n",
    "    alignments = pairwise2.align.globalxx(seq1, seq2)  # Example scoring: globalxx (match = 1, mismatch/gap = 0)\n",
    "    aligned_s1, aligned_s2 = alignments[0][:2]  # Extract the first alignment's sequences\n",
    "\n",
    "    # Example scoring scheme\n",
    "    match = 2\n",
    "    mismatch = -1\n",
    "    gap_open = -2\n",
    "    gap_extend = -1\n",
    "\n",
    "    # Compute scores using custom functions\n",
    "    computed_score = getScore(aligned_s1, aligned_s2, match, mismatch, gap_open, gap_extend)\n",
    "\n",
    "    # Biopython computed score\n",
    "    biopython_score = alignments[0][2]  # Score is part of the alignment tuple\n",
    "\n",
    "    # Print results\n",
    "    print(\"Aligned Sequences:\")\n",
    "    print(aligned_s1)\n",
    "    print(aligned_s2)\n",
    "    print(\"\\nCustom Computed Metrics:\")\n",
    "    print(\"Matches:\", countMatches(aligned_s1, aligned_s2))\n",
    "    print(\"Mismatches:\", countMismatches(aligned_s1, aligned_s2))\n",
    "    print(\"Gap Opens:\", countGapOpens(aligned_s1, aligned_s2))\n",
    "    print(\"Gap Extensions:\", countGapExtensions(aligned_s1, aligned_s2))\n",
    "    print(\"Custom Score:\", computed_score)\n",
    "    print(\"\\nBiopython Alignment Score:\", biopython_score)\n",
    "    print(\"\\nAlignment:\")\n",
    "    print(format_alignment(*alignments[0]))\n",
    "\n",
    "# Call the test function\n",
    "test_alignment(\"IL12A.fasta\", \"IL12B.fasta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIOINFORMATICS STRONGHOLD EXERCISES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 211 288 319 394 484 540 554 605 633 776 795 803 871 883 913 955 966 1003 1097 1250 1311 1335 1350 1356 1457 1525 1584 1587 1677 1706 1765 1766 1790 1797 1810 1816 1857 1863 1898 1926 1959 1986 2004 2032 2036 2053 2067 2122 2143 2182 2288 2400 2416 2468 2473 2487 2493 2507 2555 2584 2656 2753 2799 2834 2905 2942 2957 2994 3030 3153 3386 3395 3455 3473 3640 3718 3785 3806 3873 3877 3916 3980 4117 4135 4152 4209 4273 4291 4329 4363 4444 4480 4497 4506 4507 4527 4583 4622 4809 4815 4818 4851 4866 4867 4931 4945 4966 5012 5033 5063 5150 5231 5233 5296 5299 5350 5381 5413 5494 5517 5706 5740 5742 5796 5806 5943 5962 5967 5977 6024 6045 6055 6141 6236 6250 6267 6315 6316 6367 6577 6620 6639 6647 6708 6751 6769 6782 6818 6909 6951 6994 7032 7140 7179 7183 7251 7255 7267 7412 7556 7608 7656 7710 7814 7857 7894 7976 8014 8082 8119 8126 8127 8151 8196 8286 8332 8334 8506\n",
      "8658 8649 8590 8583 8568 8551 8547 8544 8531 8469 8397 8392 8375 8350 8335 8312 8308 8203 8194 8179 8137 8081 8069 8059 8025 8006 7934 7903 7841 7734 7682 7654 7578 7500 7490 7456 7455 7407 7366 7349 7345 7318 7177 7116 7023 6845 6801 6729 6720 6627 6521 6477 6474 6436 6430 6404 6395 6354 6338 6290 6279 6213 6201 6103 5973 5963 5944 5920 5840 5774 5737 5701 5700 5688 5636 5564 5520 5496 5481 5440 5419 5407 5401 5309 5242 5219 5189 5185 5162 5106 5096 5061 5040 5033 5018 4999 4923 4898 4861 4797 4766 4749 4734 4660 4659 4648 4596 4523 4486 4466 4464 4422 4328 4307 4077 4030 4023 3988 3794 3791 3750 3726 3696 3582 3565 3551 3511 3420 3388 3387 3343 3155 3139 3067 3033 2972 2878 2842 2821 2735 2664 2658 2424 2397 2326 2229 2009 1979 1970 1907 1837 1723 1692 1578 1573 1550 1513 1474 1415 1378 1342 1280 1154 1139 940 915 680 589 468 444 212 47\n"
     ]
    }
   ],
   "source": [
    "#  exercise 1 (lgis)\n",
    "def find_lis(arr):\n",
    "    from bisect import bisect_left\n",
    "\n",
    "    # Dynamic programming + binary search for LIS\n",
    "    sub = []\n",
    "    parent = [-1] * len(arr)\n",
    "    pos = []\n",
    "    \n",
    "    for i, val in enumerate(arr):\n",
    "        idx = bisect_left(sub, val)\n",
    "        if idx == len(sub):\n",
    "            sub.append(val)\n",
    "            pos.append(i)\n",
    "        else:\n",
    "            sub[idx] = val\n",
    "            pos[idx] = i\n",
    "        if idx > 0:\n",
    "            parent[i] = pos[idx - 1]\n",
    "    \n",
    "    # Reconstruct LIS\n",
    "    lis = []\n",
    "    last_index = pos[-1]\n",
    "    while last_index != -1:\n",
    "        lis.append(arr[last_index])\n",
    "        last_index = parent[last_index]\n",
    "    return lis[::-1]\n",
    "\n",
    "def main():\n",
    "    \n",
    "    with open(\"rosalind_input.txt\", \"r\") as file:\n",
    "        n = int(file.readline().strip())\n",
    "        permutation = list(map(int, file.readline().strip().split()))\n",
    "    \n",
    "    # Compute LIS and LDS\n",
    "    lis = find_lis(permutation)\n",
    "    lds = find_lis([-x for x in permutation])\n",
    "    lds = [-x for x in lds]\n",
    "    \n",
    "    # Output \n",
    "    print(\" \".join(map(str, lis)))\n",
    "    print(\" \".join(map(str, lds)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 2 (sseq)\n",
    "def parse_fasta(filepath):\n",
    "    \"\"\"Parses a FASTA file and returns a list of sequences.\"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        sequences = []\n",
    "        current_seq = []\n",
    "        for line in file:\n",
    "            if line.startswith('>'):\n",
    "                if current_seq:\n",
    "                    sequences.append(''.join(current_seq))\n",
    "                    current_seq = []\n",
    "            else:\n",
    "                current_seq.append(line.strip())\n",
    "        if current_seq:\n",
    "            sequences.append(''.join(current_seq))\n",
    "    return sequences\n",
    "\n",
    "def find_subsequence_indices(s, t):\n",
    "    \"\"\"Finds one collection of indices in s where t appears as a subsequence.\"\"\"\n",
    "    indices = []\n",
    "    start = 0\n",
    "    for char in t:\n",
    "        start = s.find(char, start)  # Find the character starting from the current position\n",
    "        if start == -1:\n",
    "            return []  # If a character is not found, subsequence doesn't exist\n",
    "        indices.append(start + 1)  # Convert to 1-based index\n",
    "        start += 1\n",
    "    return indices\n",
    "\n",
    "# Main logic\n",
    "file_path = \"rosalind_input.txt\"  # Replace with the actual file path\n",
    "sequences = parse_fasta(file_path)\n",
    "\n",
    "if len(sequences) != 2:\n",
    "    raise ValueError(f\"Expected exactly 2 sequences in the input, but found {len(sequences)}.\")\n",
    "\n",
    "s, t = sequences[:2]  # Take the first two sequences\n",
    "\n",
    "indices = find_subsequence_indices(s, t)\n",
    "if indices:\n",
    "    print(\" \".join(map(str, indices)))\n",
    "else:\n",
    "    print(\"No subsequence found.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCTGG\n"
     ]
    }
   ],
   "source": [
    "#exercise 2 (lcsq)\n",
    "def read_fasta(file_path):\n",
    "    \"\"\"Reads a FASTA file and returns the sequences as a tuple.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().strip().split('>')\n",
    "        sequences = []\n",
    "        for line in lines:\n",
    "            if line:\n",
    "                parts = line.split('\\n')\n",
    "                sequences.append(''.join(parts[1:]))\n",
    "        return tuple(sequences)\n",
    "\n",
    "def longest_common_subsequence(s, t):\n",
    "    m, n = len(s), len(t)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    \n",
    "    # Fill DP table\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if s[i - 1] == t[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "    \n",
    "    # Backtrack to find the LCS\n",
    "    i, j = m, n\n",
    "    lcs = []\n",
    "    while i > 0 and j > 0:\n",
    "        if s[i - 1] == t[j - 1]:\n",
    "            lcs.append(s[i - 1])\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif dp[i - 1][j] > dp[i][j - 1]:\n",
    "            i -= 1\n",
    "        else:\n",
    "            j -= 1\n",
    "    \n",
    "    return ''.join(reversed(lcs))\n",
    "\n",
    "\n",
    "input_file = 'rosalind_input.txt'  \n",
    "s, t = read_fasta(input_file)\n",
    "lcs = longest_common_subsequence(s, t)\n",
    "\n",
    "# Output \n",
    "print(lcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#exercise 4 (edit)\n",
    "def parse_fasta(filepath):\n",
    "    \"\"\"Parses a FASTA file and returns a list of sequences.\"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        sequences = []\n",
    "        current_seq = []\n",
    "        for line in file:\n",
    "            if line.startswith('>'):\n",
    "                if current_seq:\n",
    "                    sequences.append(''.join(current_seq))\n",
    "                    current_seq = []\n",
    "            else:\n",
    "                current_seq.append(line.strip())\n",
    "        if current_seq:\n",
    "            sequences.append(''.join(current_seq))\n",
    "    return sequences\n",
    "\n",
    "def edit_distance(s, t):\n",
    "    \"\"\"Calculates the edit distance between two strings s and t.\"\"\"\n",
    "    m, n = len(s), len(t)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    # Base cases\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    # Fill the dp table\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if s[i - 1] == t[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = min(\n",
    "                    dp[i - 1][j] + 1,    # Deletion\n",
    "                    dp[i][j - 1] + 1,    # Insertion\n",
    "                    dp[i - 1][j - 1] + 1 # Substitution\n",
    "                )\n",
    "\n",
    "    return dp[m][n]\n",
    "\n",
    "\n",
    "file_path = \"rosalind_input.txt\"  \n",
    "sequences = parse_fasta(file_path)\n",
    "\n",
    "if len(sequences) != 2:\n",
    "    raise ValueError(f\"Expected exactly 2 sequences in the input, but found {len(sequences)}.\")\n",
    "\n",
    "s, t = sequences\n",
    "result = edit_distance(s, t)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "PRETTY--\n",
      "PR-TTEIN\n"
     ]
    }
   ],
   "source": [
    "#exercise 5 (edita)\n",
    "def read_fasta(file_path):\n",
    "    \"\"\"Reads a FASTA file and returns the sequences as a tuple.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().strip().split('>')\n",
    "        sequences = []\n",
    "        for line in lines:\n",
    "            if line:\n",
    "                parts = line.split('\\n')\n",
    "                sequences.append(''.join(parts[1:]))\n",
    "        return tuple(sequences)\n",
    "\n",
    "def edit_distance_alignment(s, t):\n",
    "    m, n = len(s), len(t)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    \n",
    "    # Base cases\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j\n",
    "    \n",
    "    # Fill DP table\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if s[i - 1] == t[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
    "    \n",
    "    # Backtrack to find the alignment\n",
    "    i, j = m, n\n",
    "    s_aligned, t_aligned = [], []\n",
    "    \n",
    "    while i > 0 or j > 0:\n",
    "        if i > 0 and j > 0 and s[i - 1] == t[j - 1]:\n",
    "            s_aligned.append(s[i - 1])\n",
    "            t_aligned.append(t[j - 1])\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and dp[i][j] == dp[i - 1][j] + 1:\n",
    "            s_aligned.append(s[i - 1])\n",
    "            t_aligned.append('-')\n",
    "            i -= 1\n",
    "        elif j > 0 and dp[i][j] == dp[i][j - 1] + 1:\n",
    "            s_aligned.append('-')\n",
    "            t_aligned.append(t[j - 1])\n",
    "            j -= 1\n",
    "        else:\n",
    "            s_aligned.append(s[i - 1])\n",
    "            t_aligned.append(t[j - 1])\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "    \n",
    "    s_aligned = ''.join(reversed(s_aligned))\n",
    "    t_aligned = ''.join(reversed(t_aligned))\n",
    "    \n",
    "    return dp[m][n], s_aligned, t_aligned\n",
    "\n",
    "\n",
    "input_file = 'rosalind_input.txt'\n",
    "s, t = read_fasta(input_file)\n",
    "edit_distance, s_aligned, t_aligned = edit_distance_alignment(s, t)\n",
    "\n",
    "# output\n",
    "print(edit_distance)\n",
    "print(s_aligned)\n",
    "print(t_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#exercise 6 (ctea)\n",
    "def read_fasta(file_path):\n",
    "    \"\"\"Reads a FASTA file and returns the sequences as a tuple.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().strip().split('>')\n",
    "        sequences = []\n",
    "        for line in lines:\n",
    "            if line:\n",
    "                parts = line.split('\\n')\n",
    "                sequences.append(''.join(parts[1:]))\n",
    "        return tuple(sequences)\n",
    "\n",
    "def optimal_alignment_count(s, t):\n",
    "    MOD = 134217727\n",
    "    m, n = len(s), len(t)\n",
    "    \n",
    "    # Initialize DP and count tables\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    count = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    \n",
    "    # Base cases\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i\n",
    "        count[i][0] = 1\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j\n",
    "        count[0][j] = 1\n",
    "\n",
    "    # Fill DP and count tables\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            cost = 0 if s[i - 1] == t[j - 1] else 1\n",
    "            \n",
    "            # Calculate the minimum edit distance\n",
    "            dp[i][j] = min(\n",
    "                dp[i - 1][j - 1] + cost,  # Match/mismatch\n",
    "                dp[i - 1][j] + 1,         # Deletion\n",
    "                dp[i][j - 1] + 1          # Insertion\n",
    "            )\n",
    "            \n",
    "            # Count the ways to reach dp[i][j]\n",
    "            if dp[i][j] == dp[i - 1][j - 1] + cost:\n",
    "                count[i][j] += count[i - 1][j - 1]\n",
    "            if dp[i][j] == dp[i - 1][j] + 1:\n",
    "                count[i][j] += count[i - 1][j]\n",
    "            if dp[i][j] == dp[i][j - 1] + 1:\n",
    "                count[i][j] += count[i][j - 1]\n",
    "            \n",
    "            # Apply modulo to keep numbers manageable\n",
    "            count[i][j] %= MOD\n",
    "\n",
    "    # Result is in count[m][n]\n",
    "    return count[m][n]\n",
    "\n",
    "\n",
    "input_file = 'rosalind_input.txt'  \n",
    "s, t = read_fasta(input_file)\n",
    "result = optimal_alignment_count(s, t)\n",
    "\n",
    "# Output \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#exercise 7 (glob)\n",
    "import numpy as np\n",
    "\n",
    "def parse_fasta(filepath):\n",
    "    \"\"\"Parses a FASTA file and returns a list of sequences.\"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        sequences = []\n",
    "        current_seq = []\n",
    "        for line in file:\n",
    "            if line.startswith('>'):\n",
    "                if current_seq:\n",
    "                    sequences.append(''.join(current_seq))\n",
    "                    current_seq = []\n",
    "            else:\n",
    "                current_seq.append(line.strip())\n",
    "        if current_seq:\n",
    "            sequences.append(''.join(current_seq))\n",
    "    return sequences\n",
    "\n",
    "def load_blosum62():\n",
    "    \"\"\"Returns the BLOSUM62 scoring matrix as a dictionary.\"\"\"\n",
    "    blosum62_data = \"\"\"\n",
    "       A  R  N  D  C  Q  E  G  H  I  L  K  M  F  P  S  T  W  Y  V\n",
    "    A  4 -1 -2 -2  0 -1 -1  0 -2 -1 -1 -1 -1 -2 -1  1  0 -3 -2  0\n",
    "    R -1  5  0 -2 -3  1  0 -2  0 -3 -2  2 -1 -3 -2 -1 -1 -3 -2 -3\n",
    "    N -2  0  6  1 -3  0  0  0  1 -3 -3  0 -2 -3 -2  1  0 -4 -2 -3\n",
    "    D -2 -2  1  6 -3  0  2 -1 -1 -3 -4 -1 -3 -3 -1  0 -1 -4 -3 -3\n",
    "    C  0 -3 -3 -3  9 -3 -4 -3 -3 -1 -1 -3 -1 -2 -3 -1 -1 -2 -2 -1\n",
    "    Q -1  1  0  0 -3  5  2 -2  0 -3 -2  1  0 -3 -1  0 -1 -2 -1 -2\n",
    "    E -1  0  0  2 -4  2  5 -2  0 -3 -3  1 -2 -3 -1  0 -1 -3 -2 -2\n",
    "    G  0 -2  0 -1 -3 -2 -2  6 -2 -4 -4 -2 -3 -3 -2  0 -2 -2 -3 -3\n",
    "    H -2  0  1 -1 -3  0  0 -2  8 -3 -3 -1 -2 -1 -2 -1 -2 -2  2 -3\n",
    "    I -1 -3 -3 -3 -1 -3 -3 -4 -3  4  2 -3  1  0 -3 -2 -1 -3 -1  3\n",
    "    L -1 -2 -3 -4 -1 -2 -3 -4 -3  2  4 -2  2  0 -3 -2 -1 -2 -1  1\n",
    "    K -1  2  0 -1 -3  1  1 -2 -1 -3 -2  5 -1 -3 -1  0 -1 -3 -2 -2\n",
    "    M -1 -1 -2 -3 -1  0 -2 -3 -2  1  2 -1  5  0 -2 -1 -1 -1 -1  1\n",
    "    F -2 -3 -3 -3 -2 -3 -3 -3 -1  0  0 -3  0  6 -4 -2 -2  1  3 -1\n",
    "    P -1 -2 -2 -1 -3 -1 -1 -2 -2 -3 -3 -1 -2 -4  7 -1 -1 -4 -3 -2\n",
    "    S  1 -1  1  0 -1  0  0  0 -1 -2 -2  0 -1 -2 -1  4  1 -3 -2 -2\n",
    "    T  0 -1  0 -1 -1 -1 -1 -2 -2 -1 -1 -1 -1 -2 -1  1  5 -2 -2  0\n",
    "    W -3 -3 -4 -4 -2 -2 -3 -2 -2 -3 -2 -3 -1  1 -4 -3 -2 11  2 -3\n",
    "    Y -2 -2 -2 -3 -2 -1 -2 -3  2 -1 -1 -2 -1  3 -3 -2 -2  2  7 -1\n",
    "    V  0 -3 -3 -3 -1 -2 -2 -3 -3  3  1 -2  1 -1 -2 -2  0 -3 -1  4\n",
    "    \"\"\"\n",
    "    lines = blosum62_data.strip().split(\"\\n\")\n",
    "    amino_acids = lines[0].split()\n",
    "    matrix = {}\n",
    "    for i, line in enumerate(lines[1:]):\n",
    "        row = line.split()\n",
    "        matrix[amino_acids[i]] = {amino_acids[j]: int(row[j + 1]) for j in range(len(amino_acids))}\n",
    "    return matrix\n",
    "\n",
    "def max_alignment_score(s, t, blosum62, gap_penalty):\n",
    "    \"\"\"Calculates the maximum alignment score between s and t using BLOSUM62 and gap penalty.\"\"\"\n",
    "    m, n = len(s), len(t)\n",
    "    dp = np.zeros((m + 1, n + 1), dtype=int)\n",
    "\n",
    "    # Initialize base cases\n",
    "    for i in range(1, m + 1):\n",
    "        dp[i][0] = dp[i - 1][0] - gap_penalty\n",
    "    for j in range(1, n + 1):\n",
    "        dp[0][j] = dp[0][j - 1] - gap_penalty\n",
    "\n",
    "    # Fill the dp table\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            match = dp[i - 1][j - 1] + blosum62[s[i - 1]][t[j - 1]]\n",
    "            delete = dp[i - 1][j] - gap_penalty\n",
    "            insert = dp[i][j - 1] - gap_penalty\n",
    "            dp[i][j] = max(match, delete, insert)\n",
    "\n",
    "    return dp[m][n]\n",
    "\n",
    "\n",
    "file_path = \"rosalind_input.txt\" \n",
    "sequences = parse_fasta(file_path)\n",
    "\n",
    "if len(sequences) != 2:\n",
    "    raise ValueError(f\"Expected exactly 2 sequences in the input, but found {len(sequences)}.\")\n",
    "\n",
    "s, t = sequences\n",
    "gap_penalty = 5\n",
    "blosum62 = load_blosum62()\n",
    "\n",
    "alignment_score = max_alignment_score(s, t, blosum62, gap_penalty)\n",
    "print(alignment_score)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
